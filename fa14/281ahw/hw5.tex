\documentclass[12pt]{article}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newcommand{\E}{\operatorname{\mathbb{E}}}
\renewcommand{\P}{\operatorname{\mathbb{P}}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\Cov}{\operatorname{Cov}}
\newcommand{\Cor}{\operatorname{Cor}}
\newcommand{\expect}[1]{\mathbb{E}\left(#1\right)}
\newcommand{\pr}[1]{\mathbb{P}\left(#1\right)}
\newcommand{\var}[1]{\operatorname{Var}\left(#1\right)}
\newcommand{\cov}[1]{\operatorname{Cov}\left(#1\right)}
%\newcommand{\cor}[1]{\operatorname{Cor}\left(#1\right)}
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\def\iid{\stackrel{\rm iid}{\sim}}
\def\Bin{\text{Bin}}
\def\Unif{\text{Unif}}
\def\lsto{\stackrel{\rm sto}{\leq}}
\def\gsto{\stackrel{\rm sto}{\geq}}

\begin{document}
% --------------------------------------------------------------
% Start here
% --------------------------------------------------------------
\title{Homework 5}%replace X with the appropriate number
\author{MATH 281A} %if necessary, replace with your course title
\maketitle
\begin{exercise}{5.1}
\end{exercise}

Just make sure that the integration does not blow up to infinity. 

\begin{exercise}{5.2}
\end{exercise}

Construct a situation that the parameters are not equal when the densities are the same. This implies there exists no identifiability.

\begin{exercise}{5.31}
\end{exercise}

This is a standard move. Be careful when you combining the exponential powers.

\begin{exercise}{5.32}
\end{exercise}

Since the transformation $Y \rightarrow c\log Y$ is continuous, we can write out the density of $c\log Y$ then verify that this is an exponential family.

Pay attention that $\alpha$ is fixed here so treat it as a constant.

\begin{exercise}{Extra}
\end{exercise}

1.Show that $X$ is not complete when $\P (X = i) = i\theta, i=1,2$ and $\P(X = 3) = 1-3\theta$

Since we have $\P(X =2) = 2 \P (X=1)$ for all $\theta$, we can construct a statistic with expectation zero based on that. (Which function has the expectation as probabilities?)

To show completeness in the other situation, just use the identity of the polynomials. Notice that a polynomial is zero in an interval of any length if and only if all the coefficients are zero. 

2. It is straight forward to show that Cauchy and uniform distributions are not exponential families.

For Weibull, it is also not hard.

3. Finite collection of distributions are exponential families. Carefully use the indicator function on the finite parameter space (to make the indicators of the parameters work as indicators of densities)

4. UMVUE for geometric distribution:

For $1/p$, it is straight forward since $\sum X_i$ is sufficient and complete (Why?). Construct an unbiased estimator based on that is trivial (How?)

For $p$, use the fact that the summation of independent geometric distributions is following negative binomial distributions, and use Method I to find the UMVUE.

5. (Ex 6.21) For normal random variables such that $CV = 1$, $(\sum X_i, \sum X^2_i)$ is not complete.

Compute $\E (\bar{X}^2)$ and $\E X^2$ and adjust them with some constant until they result the same value in the name of $\mu^2$.

6. To show that $(\sum X_i, \sum X_i^2 , \sum X_i^3)$ is not complete for the location family $ f_\theta(x) = Ce^{-(x-\theta)^4}$ by using $(\sum X_i , \sum X^2_i)$.

Consider the fact that
$$
\E (\bar{X}^2) = \theta^2 + \sigma^2/n
$$
$$
\E (X_i^2) = \theta^2 + \sigma^2
$$
where $\sigma^2 = var(X_i)$ (why do we have these two equations?)

Next step is to notice that $\sigma^2$ does not change with $\theta$ (why?). Based on this we can construct an unbiased estimator of zero.


% --------------------------------------------------------------
% You don't have to mess with anything below this line.
% --------------------------------------------------------------
\end{document} 